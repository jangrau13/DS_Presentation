{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be4c8718",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 588.3 MB 73 kB/s  eta 0:00:013     |██████████████████████▉         | 419.0 MB 3.6 MB/s eta 0:00:47\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 32.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in ./venv/lib/python3.8/site-packages (from tensorflow) (22.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 29.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in ./venv/lib/python3.8/site-packages (from tensorflow) (44.0.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.20 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 29.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 41.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[K     |████████████████████████████████| 232 kB 29.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 50.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.1.1 in ./venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in ./venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (5.1.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 30.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 32.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: zipp>=0.5 in ./venv/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
      "Installing collected packages: protobuf, grpcio, termcolor, wrapt, tensorflow-io-gcs-filesystem, werkzeug, wheel, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, absl-py, oauthlib, certifi, urllib3, charset-normalizer, requests, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, tensorboard-plugin-wit, markdown, tensorboard, google-pasta, opt-einsum, flatbuffers, tensorflow-estimator, gast, typing-extensions, keras, libclang, h5py, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.12.7 charset-normalizer-2.1.1 flatbuffers-22.12.6 gast-0.4.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 keras-2.11.0 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1 typing-extensions-4.4.0 urllib3-1.26.13 werkzeug-2.2.2 wheel-0.38.4 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "# install RISE with https://rise.readthedocs.io/en/stable/installation.html\n",
    "#!pip3 install -U scikit-learn\n",
    "#!pip3 install -U RISE\n",
    "#!pip3 install -U matplotlib\n",
    "#!pip3 install -U numpy\n",
    "# all imports\n",
    "!pip3 install -U tensorflow\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cceec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 6: Specific Problem of Natural Language Processing\n",
    "\n",
    "## by Ziwei Chen, Stephan Nef, Lukas Bamert and Jan Grau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a89b9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "\n",
    "1. Words to mathematical representation\n",
    "2. Embedding the problem into already learnt\n",
    "3. Transformer Encoder\n",
    "    1. Self-Attention\n",
    "    2. position-wise Feedforward Networks\n",
    "    3. Residucal connection and Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da4dee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to NLP\n",
    "give examples on application, where it is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33522ef0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Words to mathematical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478cf3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "explain the problems of word to NLP, why we need to transform the words into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5606a2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take the formula from chapter 6.1 show it with some explanation in markdown and create a code example. Example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79879797",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 0 1 1 1 1 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "          'Text of first Lukas.',\n",
    "          'Text of the second document made longer.',\n",
    "          'Number three is new.',\n",
    "          'This is number four.',\n",
    "]\n",
    "# learn the vocabulary and store CountVectorizer sparse matrix in X\n",
    "X = vectorizer.fit_transform(corpus)# columns of X correspond to the result of this method\n",
    "vectorizer.get_feature_names_out() == (\n",
    "    ['document', 'first', 'four', 'is', 'longer',\n",
    "     'made', 'number', 'of', 'second', 'text',\n",
    "     'the', 'this', 'three', 'new', 'Lukas'])# retrieving the matrix in the numpy form\n",
    "print(X.toarray())# transforming a new document according to learn vocabulary\n",
    "vectorizer.transform(['A new Lukas is three.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d409ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "explain advantages/disadvantages of Word Embeddings as calculated above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf7d06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "introduce the formula $x_i = Mt_i$ and $x_i^\\star= x_i +p_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0307e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If found, give code example for the formulas otherwise use an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef45e8a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#insert code for formula above or use an image to explain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc66728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Semantic Similarity\n",
    "\n",
    "explain formula $w_{AB} = v_A'v_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecda2c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# code example of formula above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f29547",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embed previous learnt methods to NLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a510c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### modelling it as FIR\n",
    "- draw some relations back to FIR with an example and image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552ca05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### modelling it as IIR\n",
    "- draw some relations back to IIR with an example and image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c7f6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### modelling it as RNN\n",
    "- draw some relations back to discrete linear systems with an example and image\n",
    "- introduce the new formula $h_t = H(h_{t-1}, x_{t-1})$ and $y_t = Y(h_t,x_t)$\n",
    "- explain the differences between classical RNNs and our application\n",
    "- also with the new formula $h_t = H(h_{t-1}, x_{t})$ and $y_t = Y(h_t)$\n",
    "- explain the vanishing gradient problem in RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a9ee1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## from RNN to LSTMs\n",
    "- introduce the state formula $c_t = C(h_{t-1}, x_t, c_{t-1})$\n",
    "- introduce formula 6.13\n",
    "- introduce the three gates (forget gate, input gate and output gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683c8855",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# code to show the Hadamard operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c364767",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# code to explain the gates (if easily found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e5661",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### improvements for RNNs\n",
    "- bidirectional sequencing\n",
    "- example with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6ff56",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![Attention is all you need](attention.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb23dd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention\n",
    "\n",
    "Remember the problem of FIR filters? The length of the filter is too short for the actual input and quality of the data of the input may differ.\n",
    "\n",
    "There is a solution to this: $\\underline{attention}$.\n",
    "\n",
    "Let $v = [v_1,..., v_n]$ be a sequence of input vectors.\n",
    "\n",
    "Then we can define a context vector $c$ as $c= \\sum_{i=1}^n \\alpha_iv_i$.\n",
    "\n",
    "This can be extrapolated to different context vectors, each describing different contexts $j$:\n",
    "\n",
    "$$c_j = \\sum_{i=1}^n \\alpha_{ji}v_i $$\n",
    "\n",
    "\n",
    "where $\\alpha_{ji}$ is an attention weight from input $i$ to output $j$. A good way to achieve this is to use the softmax function:\n",
    "\n",
    "$$\\alpha_{ji} = \\frac{e^{g_{ji}}}{\\sum_{k=1}^ne^{g_{jk}}}$$\n",
    "\n",
    "where $g_{ji}$ is using an alignment model to tell about the similarity of two vectors:\n",
    "\n",
    "$$ g_{ji} = \\frac{q_j'k_i}{\\sqrt{k}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0057c84b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a context vector calculation in pratice\n",
    "\n",
    "# let's try to figure out the market value of newcomer Güven \n",
    "# given our scouting DB with current market values of known players\n",
    "\n",
    "v = {}\n",
    "v[\"messi\"] = 80\n",
    "v[\"lewandowski\"] = 40\n",
    "v[\"maguire\"] = -25\n",
    "\n",
    "# since we already have an example of cosine similarity g_ji is given here\n",
    "\n",
    "g = {}\n",
    "g[\"güven-messi\"] = 0.8\n",
    "g[\"güven-lewandowski\"] = 0.5\n",
    "g[\"güven-maguire\"] = -0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffffdf9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected market value of Güven:  53.83 Mio CHF\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# a litte helper\n",
    "sum_eg = 0\n",
    "for mv in g:\n",
    "    sum_eg += math.exp(g[mv])\n",
    "\n",
    "# calculate attention values\n",
    "alpha_güven_messi = math.exp(g[\"güven-messi\"])/sum_eg\n",
    "alpha_güven_lewandowski = math.exp(g[\"güven-lewandowski\"])/sum_eg\n",
    "alpha_güven_maguire = math.exp(g[\"güven-maguire\"])/sum_eg\n",
    "c = alpha_güven_messi *v[\"messi\"] + alpha_güven_lewandowski * v[\"lewandowski\"] + alpha_güven_maguire * v[\"maguire\"]\n",
    "print(\"expected market value of Güven: \", round(c,2), \"Mio CHF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712d014",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Takeaway\n",
    "\n",
    "We calculate basic attention by querying (Güven aka $q$) to keys (Messi & co, aka $k$) to get a value (market value aka $v$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c56e2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autocoding out of context\n",
    "\n",
    "Tell something about chapter 6.6. But probably after transformers are explained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb7f02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Self-Attention\n",
    "\n",
    "What if we try to calculate our $q$, $k$, and $v$ by ourselves?\n",
    "\n",
    "This process is called self-attention, where each input vector from $x = [x_1,...,x_n]$ is also query, key and value:\n",
    "\n",
    "$$x_i = q_i = k_i = v_i$$\n",
    "\n",
    "However instead of just calculating $c_j = \\sum_{i=1}^n \\alpha_{ji}v_i$ with $\\alpha_{ji} = \\frac{e^{g_{ji}}}{\\sum_{k=1}^ne^{g_{jk}}}$, it has been proven mathematically beneficial to linearly project these vectors (in our example we had a scalar value) into smaller dimensionalities. For this we use three projection matrices $W^Q$, $W^K$, $W^V$. This will give us the following equations:\n",
    "\n",
    "$$ q_i^\\star = W^Qq_i, k_i^\\star = W^Kk_i,v_i^\\star = W^Vv_i$$\n",
    "\n",
    "\n",
    "These $W$ play an essential role in the learning. Since the attention mechanism does not contain trainable parameters. Therefore given fixed inputs vectors, we need to learn the elements of the $W$'s. Also note that having two different matrices $W^Q$ and $W^K$ we will have asymetric relationships between the input vector elements.\n",
    "\n",
    "In the end we can calculate $c_j =  \\sum_{i=1}^n \\alpha_{ji}v_i^\\star$ for each element $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50b60adb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# input vector (maybe take values from Stephan/Ziwei)\n",
    "x = np.array([np.random.random_sample(8) for x in range(3)])\n",
    "\n",
    "# we need to set the dimensions\n",
    "d_model = len(x[0]) # always the length of the input vectors\n",
    "d_q = d_model // 4 # theoretically freely choosable to linear transform the projection matrix\n",
    "d_v = d_model // 2 # can be different for the values, but usually not\n",
    "\n",
    "# generate the three projections matrices\n",
    "W_Q = np.random.random_sample((d_q, d_model)) # in a trainable model, those would be trained instead of random\n",
    "W_K = np.random.random_sample((d_q, d_model)) # in a trainable model, those would be trained instead of random\n",
    "W_V = np.random.random_sample((d_v, d_model)) # in a trainable model, those would be trained instead of random\n",
    "\n",
    "print(W_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "417439dd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "# calculate context vector c_1 (based on x_1)\n",
    "c_1 = 0\n",
    "c = np.zeros((x.shape[0], d_v))\n",
    "\n",
    "\n",
    "k_stars = np.array([np.dot(W_K, xi) for xi in x])\n",
    "q_stars = np.array([np.dot(W_Q, xi).transpose() for xi in x])\n",
    "v_stars = np.array([np.dot(W_V, xi) for xi in x])\n",
    "\n",
    "for j in range(x.shape[0]):\n",
    "    qj_star = q_stars[j]\n",
    "    all_gj = np.array([np.dot(qj_star, k_stars[i]) / np.sqrt(d_model) for i in range(x.shape[0])]) # 3x1\n",
    "    sum_g = np.sum(np.array([math.exp(all_gj[i]) for i in range(x.shape[0])]))\n",
    "    alpha_j = np.array([math.exp(all_gj[i]) / sum_g for i in range(x.shape[0])])\n",
    "    c[j] = np.sum([np.dot(alpha_j[i], v_stars[i]) for i in range(x.shape[0])], axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e332d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multihead Attention\n",
    "Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "970726dd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# input vector (maybe take values from Stephan/Ziwei)\n",
    "x = np.array([np.random.random_sample(8) for x in range(3)])\n",
    "\n",
    "# we need to set the dimensions\n",
    "d_model = len(x[0]) # always the length of the input vectors\n",
    "d_q = d_model // 4 # theoretically freely choosable to linear transform the projection matrix\n",
    "d_v = d_model // 2 # can be different for the values, but usually not\n",
    "h_count = 3 # Header Count\n",
    "\n",
    "W_Q = np.random.random_sample((h_count,d_q, d_model))\n",
    "W_K = np.random.random_sample((h_count,d_q, d_model))\n",
    "W_V = np.random.random_sample((h_count,d_v, d_model))\n",
    "\n",
    "\n",
    "c_jh = np.zeros((x.shape[0], h_count, d_v))\n",
    "\n",
    "for hi in range(h_count):\n",
    "    k_stars = np.array([np.dot(W_K[hi], xi) for xi in x])\n",
    "    q_stars = np.array([np.dot(W_Q[hi], xi).transpose() for xi in x])\n",
    "    v_stars = np.array([np.dot(W_V[hi], xi) for xi in x])\n",
    "    \n",
    "    for j in range(x.shape[0]):\n",
    "        qj_star = q_stars[j]\n",
    "        all_gj = np.array([np.dot(qj_star, k_stars[i]) / np.sqrt(d_model) for i in range(x.shape[0])]) # 3x1\n",
    "        sum_g = np.sum(np.array([math.exp(all_gj[i]) for i in range(x.shape[0])]))\n",
    "        alpha_j = np.array([math.exp(all_gj[i]) / sum_g for i in range(x.shape[0])])\n",
    "        c_jh[j][hi] = np.sum([np.dot(alpha_j[i], v_stars[i]) for i in range(x.shape[0])], axis=0)\n",
    "\n",
    "W_O = np.random.random_sample((x.shape[0],d_model, h_count*d_v))\n",
    "\n",
    "z = np.zeros((x.shape[0], d_model))\n",
    "c = c_jh.reshape(x.shape[0], h_count * d_v)\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    z[i] = np.dot(W_O[i], c[i])\n",
    "\n",
    "\n",
    "\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06945c57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pointwise Feedforward Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73e7411d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (3, 8)\n"
     ]
    }
   ],
   "source": [
    "d_inner = d_model * 4\n",
    "\n",
    "W_1 = np.random.random_sample((d_inner, d_model))\n",
    "W_2 = np.random.random_sample((d_model, d_inner))\n",
    "b_1 = np.random.random_sample((d_inner))\n",
    "b_2 = np.random.random_sample((d_model))\n",
    "relu = np.zeros((d_inner))\n",
    "y = np.zeros((x.shape[0], d_model))\n",
    "for i in range(x.shape[0]):\n",
    "    hidden_layer = np.maximum(np.dot(W_1, z[i] ) + b_1, d_inner)\n",
    "    y[i] = np.dot(W_2, hidden_layer) + b_2\n",
    "print(\"Y\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b437a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Residual Connection and Layer Optimization\n",
    "\n",
    "- aim to improve the converge of optimzation algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee47b18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Residual Connection\n",
    "\n",
    "Substitue $y = f(x,p)$ by $y = x + g(x,q)$ where q and p are parameter vectors\n",
    "\n",
    "This means that $g(x,q) = f(x,p) - x$\n",
    "\n",
    "- $ g(x,q)$ can be easier to optimize if f is close to the identity function $id(x) = x$\n",
    "- $ q(x,q)$ learns how much the input x needs to change\n",
    "\n",
    "- if $initial weights = 0$ without residual, then $output\\approx zerofunction$\n",
    "- if $initial weights = 0$ with residual, then $output \\approx identity(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11493271",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reasoning:\n",
    "\n",
    "- gradient of objective function E ( Error function) $E(y)$.\n",
    "- Chain-Rule\n",
    "$$ E'(y) = E'(y)\\cdot y'$$\n",
    "\n",
    "\n",
    "$$ \\frac{\\delta E}{\\delta y} = \\frac{\\delta E}{\\delta y} \\frac{\\delta y}{\\delta x}$$\n",
    "\n",
    "Without residual: y = Px\n",
    "\n",
    "$$ \\frac{\\delta E}{\\delta y} \\frac{\\delta y}{\\delta x} = \\frac{\\delta E}{\\delta y}P$$\n",
    "\n",
    "With residual connection: y = x + Qx, I = Identy Matrix (derivate of x)\n",
    "\n",
    "$$ \\frac{\\delta E}{\\delta y} \\frac{\\delta y}{\\delta x} = \\frac{\\delta E}{\\delta y}(I+Q)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d2033d29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[0. 0. 0.]]], shape=(1, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,3))\n",
    "result = layers.MultiHeadAttention(key_dim=2, num_heads=2, use_bias=False, kernel_initializer='zeros')(inputs, inputs)\n",
    "#result = layers.Add()([inputs, result])\n",
    "model = keras.models.Model(inputs=inputs, outputs=result)\n",
    "test_input = tf.constant([[[1,2,3]]])\n",
    "result = model(test_input)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
